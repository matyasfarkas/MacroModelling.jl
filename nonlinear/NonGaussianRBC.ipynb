{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17bf5e47-b743-4142-94dc-a471196683d5",
   "metadata": {},
   "source": [
    "## Some State Space Model Tricks \n",
    "\n",
    "In this notebook, I plan to explore a few tricks that can be easily implemented for Bayesian estimation of state space models when using the joint likelihood approach described in [\"Differentiable State-Space Models\n",
    "and Hamiltonian Monte Carlo Estimation\"](https://donskerclass.github.io/files/pdf/hmc_dssm.pdf) and implemented in the accompanying library [DifferentiableStateSpaceModels.jl](https://github.com/HighDimensionalEconLab/DifferentiableStateSpaceModels.jl). For an introduction to use of that library to fit linear and nonlinear versions of a simple model (a Real Business Cycle model), see the [tutorial notebok](https://nbviewer.org/github/HighDimensionalEconLab/DifferentiableStateSpaceModels.jl/blob/main/notebooks/estimate_rbc.ipynb). \n",
    "\n",
    "This notebook will build on that one (with much of the code copied), to describe how to introduce two easy-to-add but empirically very helpful features\n",
    "\n",
    "1. Non-Gaussian (Student t) innovations, to better describe the heavy-tailed nature of economic series and measurements.\n",
    "2. Stochastic volatility, to match observed heteroskedasticity in economic data.\n",
    "\n",
    "These will be introduced using the modeling approach of [Chib, Shin, and Tan (2021)](https://docs.google.com/a/slu.edu/viewer?a=v&pid=sites&srcid=c2x1LmVkdXx0YW5mfGd4OmU1MTI5NTNmNTc2ZmRlOQ) in the context of a linearized model, for which, due to certainty equivalence, the error process and the equilibrium computation can be kept separate. This allows us to separate the DSGE solver component of the problem, implemented in `DifferentiableStateSpaceModels.jl`, from the Bayesian probability model setup, which can be done in a probabilistic programming environment, here that of [Turing.jl](https://turing.ml/). \n",
    "\n",
    "The reason this becomes simple in such a language is that it separates modeling from inference, so replacing a distribution in the model just requires changing the model setup. The reason this doesn't cause any issues in the inference is that when using the joint likelihood approach to state space models (that is, just treating the latent states the same as any other parameters), the sampling algorithm doesn't rely on any features of the distribution like (conditional) Gaussianity. The NUTS sampler does need derivatives, however, which creates some implementation issues, at least for the stochastic volatility part. Fortunately these are pretty easy to get around with some coding style changes.  \n",
    "\n",
    "My goal in this is not a formal comparison of samplers (I'm sure their custom sampling algorithm is great), just an illustration of a set of things that can be done in a probabilistic programming language even without deriving new methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19126b2-6017-4203-a775-c477a511fd25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Pkg; Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9469dd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\fm007\\.julia\\registries\\General.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\fm007\\.julia\\environments\\v1.8\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\fm007\\.julia\\environments\\v1.8\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"DifferentiableStateSpaceModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\fm007\\.julia\\registries\\General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\fm007\\.julia\\environments\\v1.8\\Project.toml`\n",
      " \u001b[90m [b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.3.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\fm007\\.julia\\environments\\v1.8\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "## Pkg.add.([\"DifferentiableStateSpaceModels\" , \"DifferenceEquations\", \"LinearAlgebra\", \"Zygote\", \"Distributions\", \"DiffEqBase\", \"Symbolics\", \"Plots\", \"Random\", \"StatsPlots\",\"BenchmarkTools\",\"LaTeXStrings\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841835de-36ac-445f-801f-84c42ef9a8cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using DifferentiableStateSpaceModels, DifferenceEquations, LinearAlgebra, Zygote, Distributions, DiffEqBase, Symbolics, Plots, Random, StatsPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a62934e-861a-4f74-9433-2a9fa7ca8f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: max_order not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: max_order not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] getproperty\n",
      "   @ .\\Base.jl:31 [inlined]\n",
      " [2] PerturbationModel(mod::Module)\n",
      "   @ DifferentiableStateSpaceModels C:\\Users\\fm007\\.julia\\packages\\DifferentiableStateSpaceModels\\Rj4ZG\\src\\types.jl:35\n",
      " [3] top-level scope\n",
      "   @ C:\\Users\\fm007\\.julia\\packages\\DifferentiableStateSpaceModels\\Rj4ZG\\src\\make_perturbation_model.jl:392"
     ]
    }
   ],
   "source": [
    "#Build the RBC model\n",
    "∞ = Inf\n",
    "@variables α, β, ρ, δ, σ, Ω_1\n",
    "@variables t::Integer, k(..), z(..), c(..), q(..)\n",
    "\n",
    "x = [k, z] # states\n",
    "y = [c, q] # controls\n",
    "p = [α, β, ρ, δ, σ, Ω_1] # parameters\n",
    "\n",
    "H = [1 / c(t) - (β / c(t + 1)) * (α * exp(z(t + 1)) * k(t + 1)^(α - 1) + (1 - δ)),\n",
    "     c(t) + k(t + 1) - (1 - δ) * k(t) - q(t),\n",
    "     q(t) - exp(z(t)) * k(t)^α,\n",
    "     z(t + 1) - ρ * z(t)]  # system of model equations\n",
    "\n",
    "# analytic solutions for the steady state.  Could pass initial values and run solver and use initial values with steady_states_iv\n",
    "steady_states = [k(∞) ~ (((1 / β) - 1 + δ) / α)^(1 / (α - 1)),\n",
    "                 z(∞) ~ 0,\n",
    "                 c(∞) ~ (((1 / β) - 1 + δ) / α)^(α / (α - 1)) -\n",
    "                        δ * (((1 / β) - 1 + δ) / α)^(1 / (α - 1)),\n",
    "                 q(∞) ~ (((1 / β) - 1 + δ) / α)^(α / (α - 1))]\n",
    "\n",
    "\n",
    "Γ = [σ;;] # matrix for the 1 shock.  The [;;] notation just makes it a matrix rather than vector in julia\n",
    "η = [0; -1;;] # η is n_x * n_ϵ matrix.  The [;;] notation just makes it a matrix rather than vector in julia\n",
    "\n",
    "# observation matrix.  order is \"y\" then \"x\" variables, so [c,q,k,z] in this example\n",
    "Q = [1.0 0  0   0; # select c as first \"z\" observable\n",
    "     0   0  1.0 0] # select k as second \"z\" observable\n",
    "\n",
    "# diagonal cholesky of covariance matrix for observation noise (so these are standard deviations).  Non-diagonal observation noise not currently supported\n",
    "Ω = [Ω_1, Ω_1]\n",
    "\n",
    "# Generates the files and includes if required.  If the model is already created, then just loads\n",
    "overwrite_model_cache  = true\n",
    "model_rbc = @make_and_include_perturbation_model(\"rbc_notebook_example\", H, (; t, y, x, p, steady_states, Γ, Ω, η, Q, overwrite_model_cache)) # Convenience macro.  Saves as \".function_cache/rbc_notebook_example.jl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94caf4-5d71-42a9-80f1-bb7f0f5b7db1",
   "metadata": {},
   "source": [
    "We use as our basic model an RBC with 1 shock (productivity) and 2 observables (consumption and capital) taken from the [tutorial notebok](https://github.com/HighDimensionalEconLab/DifferentiableStateSpaceModels.jl/blob/main/notebooks/estimate_rbc.ipynb). Here's a reminder of the model equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbef281e-9393-4e58-82d9-b8cf5ad4c5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: model_rbc not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model_rbc not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:1"
     ]
    }
   ],
   "source": [
    "model_H_latex(model_rbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf4e9cb-d586-42cd-89ff-17b68b7760a5",
   "metadata": {},
   "source": [
    "Where we change from the tutorial version is that instead of using Gaussian shocks, which are traditional, we change their distribution. I'm going to start with the simplest modification, which is to change the shocks to be Student-t distributed. If this all works I will attempt to also add stochastic volatility (which requires adding a loop). I start by simulating some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee19d193-49db-4807-b477-fff60584b3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: model_rbc not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model_rbc not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:4"
     ]
    }
   ],
   "source": [
    "#Solve model at some fixed parameters\n",
    "p_f = (ρ = 0.2, δ = 0.02, σ = 0.01, Ω_1 = 0.01) # Fixed parameters\n",
    "p_d = (α = 0.5, β = 0.95) # Pseudo-true values\n",
    "m = model_rbc  # ensure notebook executed above\n",
    "sol = generate_perturbation(m, p_d, p_f) # Solution to the first-order RBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2002e93-f1d3-4896-918d-293c7ac0fd1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: Random not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Random not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:3"
     ]
    }
   ],
   "source": [
    "# Simulate T observations from a random initial condition\n",
    "T = 20\n",
    "Random.seed!(12345) #Fix seed to reproduce data\n",
    "dof = 4 #Student t degrees of freedom\n",
    "shockdist = TDist(dof) #Shocks are student-t\n",
    "\n",
    "# draw from t scaled by approximate invariant variance) for the initial condition\n",
    "x_iv = sol.x_ergodic_var * rand(shockdist,sol.n_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5631325d-ddb9-49c0-83cb-efd257f81481",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: shockdist not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: shockdist not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:2"
     ]
    }
   ],
   "source": [
    "# Generate noise sequence\n",
    "noiseshocks = rand(shockdist,T)\n",
    "noise = Matrix(noiseshocks') # the ϵ shocks are \"noise\" in DifferenceEquations for SciML compatibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f8fa84a-0b7d-4ca2-8fe8-48c539f406ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: noise not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: noise not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:2"
     ]
    }
   ],
   "source": [
    "#Solve problem forward with Student-t noise\n",
    "problem = LinearStateSpaceProblem(sol, x_iv, (0, T); noise)\n",
    "sim=solve(problem)\n",
    "# Collapse to simulated observables as a matrix  - as required by current DifferenceEquations.jl likelihood\n",
    "# see https://github.com/SciML/DifferenceEquations.jl/issues/55 for direct support of this datastructure\n",
    "z_rbc = hcat(sim.z...)\n",
    "plot(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9e424-4231-481f-9308-0005302abb94",
   "metadata": {},
   "source": [
    "That looks like a nice heavy tailed simulation: we see some big swings that might create problems for a Gaussian likelihood. To estimate, build the model in Turing, identical to the benchmark model in the tutorial notebook with Gaussian noise when implemented with the joint approach, but replacing it with Student-t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3b9f58-86eb-40d9-890d-932a04f8831c",
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching setadbackend(::Val{:zygote})\nClosest candidates are:\n  setadbackend(!Matched::Symbol) at C:\\Users\\fm007\\.julia\\packages\\AdvancedVI\\hVQ2g\\src\\ad.jl:5\n  setadbackend(!Matched::Val{:forward_diff}) at C:\\Users\\fm007\\.julia\\packages\\AdvancedVI\\hVQ2g\\src\\ad.jl:6\n  setadbackend(!Matched::Val{:forwarddiff}) at C:\\Users\\fm007\\.julia\\packages\\AdvancedVI\\hVQ2g\\src\\ad.jl:10\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching setadbackend(::Val{:zygote})\n",
      "Closest candidates are:\n",
      "  setadbackend(!Matched::Symbol) at C:\\Users\\fm007\\.julia\\packages\\AdvancedVI\\hVQ2g\\src\\ad.jl:5\n",
      "  setadbackend(!Matched::Val{:forward_diff}) at C:\\Users\\fm007\\.julia\\packages\\AdvancedVI\\hVQ2g\\src\\ad.jl:6\n",
      "  setadbackend(!Matched::Val{:forwarddiff}) at C:\\Users\\fm007\\.julia\\packages\\AdvancedVI\\hVQ2g\\src\\ad.jl:10\n",
      "  ...\n",
      "\n",
      "Stacktrace:\n",
      " [1] setadbackend(backend::Val{:zygote})\n",
      "   @ Turing.Essential C:\\Users\\fm007\\.julia\\packages\\Turing\\Suzsv\\src\\essential\\ad.jl:8\n",
      " [2] setadbackend(backend_sym::Symbol)\n",
      "   @ Turing.Essential C:\\Users\\fm007\\.julia\\packages\\Turing\\Suzsv\\src\\essential\\ad.jl:5\n",
      " [3] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:3"
     ]
    }
   ],
   "source": [
    "using Turing\n",
    "using Turing: @addlogprob!\n",
    "Turing.setadbackend(:zygote);  # Especially when we sample the latent noise, we will require high-dimensional gradients with reverse-mode AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a206e7-2f3b-4cda-93f2-9832dbb8778f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: model_rbc not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model_rbc not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:19"
     ]
    }
   ],
   "source": [
    "# Turing model definition\n",
    "@model function rbc_1_t_joint(z, m, p_f, dof, cache, settings)\n",
    "    α ~ Uniform(0.2, 0.8)\n",
    "    β ~ Uniform(0.5, 0.99)\n",
    "    p_d = (; α, β)\n",
    "    T = size(z, 2)\n",
    "    xnought ~ filldist(TDist(dof),m.n_x) #Initial shocks \n",
    "    ϵ_draw ~ filldist(TDist(dof),m.n_ϵ * T) #Shocks are t-distributed!\n",
    "    ϵ = reshape(ϵ_draw, m.n_ϵ, T)\n",
    "    sol = generate_perturbation(m, p_d, p_f, Val(1); cache, settings) \n",
    "    if !(sol.retcode == :Success)\n",
    "        @addlogprob! -Inf\n",
    "        return\n",
    "    end\n",
    "    x_iv = sol.x_ergodic_var * xnought #scale initial condition to ergodic variance\n",
    "    problem = LinearStateSpaceProblem(sol, x_iv, (0, T), observables = z, noise=ϵ)\n",
    "    @addlogprob! solve(problem, DirectIteration()).logpdf # should choose DirectIteration() by default if not provided\n",
    "end\n",
    "cache = SolverCache(model_rbc, Val(1),  [:α, :β])\n",
    "settings = PerturbationSolverSettings(; print_level = 0)\n",
    "p_f = (ρ = 0.2, δ = 0.02, σ = 0.01, Ω_1 = 0.01) # Fixed parameters\n",
    "z = z_rbc # simulated in previous steps\n",
    "turing_model = rbc_1_t_joint(z, model_rbc, p_f, dof, cache, settings) # passing observables from before \n",
    "\n",
    "n_samples = 300\n",
    "n_adapts = 50\n",
    "δ = 0.65\n",
    "alg = NUTS(n_adapts,δ)\n",
    "chain_1_joint = sample(turing_model, alg, n_samples; progress = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffccce4b-ab93-4903-b331-e97a6ad3fa45",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: chain_1_joint not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chain_1_joint not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:2"
     ]
    }
   ],
   "source": [
    "#Plot the chains and posteriors\n",
    "plot(chain_1_joint[[\"α\"]]; colordim=:parameter, legend=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e6d915d-7158-426a-aed4-91bf5f78779a",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: chain_1_joint not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chain_1_joint not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:1"
     ]
    }
   ],
   "source": [
    "plot(chain_1_joint[[\"β\"]]; colordim=:parameter, legend=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "012cfb45-108d-4c84-bf46-117677f16f69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: chain_1_joint not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chain_1_joint not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:3"
     ]
    }
   ],
   "source": [
    "#Plot true and estimated latents to see how well we backed them out\n",
    "symbol_to_int(s) = parse(Int, string(s)[9:end-1])\n",
    "ϵ_chain = sort(chain_1_joint[:, [Symbol(\"ϵ_draw[$a]\") for a in 1:21], 1], lt = (x,y) -> symbol_to_int(x) < symbol_to_int(y))\n",
    "tmp = describe(ϵ_chain)\n",
    "ϵ_mean = tmp[1][:, 2]\n",
    "ϵ_std = tmp[1][:, 3]\n",
    "plot(ϵ_mean[2:end], ribbon=2 * ϵ_std[2:end], label=\"Posterior mean\", title = \"First-Order Joint: Estimated Latents\")\n",
    "plot!(noise', label=\"True values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266652db-0db1-4a22-ac6a-5cb203a156f7",
   "metadata": {},
   "source": [
    "That's really pretty good! From the table and plots we also did a decent job with $\\alpha$ and $\\beta$, for such a short MCMC chain.\n",
    "\n",
    "So, that was changing to student-t shocks for the latent states. Once we had the data simulated, it required only **one change in the code** in the Turing model, from `MvNormal()` for multivariate normal to `filldist(Tdist())` for a collection of Student-t's. No use of fun special properties of the distribution like the scale-mixture-of-normals representation or fancy Gibbs samplers with closed form marginals were required (nor, thank heavens, anything like a particle filter), just sampling the latent states as if they were parameters. I make no guarantees that this approach is fast, but with HMC it isn't bad at all, and it is very easy, and as a bonus can be carried out with whatever distribution you want, not just well-behaved ones. So go ahead and start fitting your favorite residual error distributions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e346ad4-9308-40e2-9d00-e915e13724c5",
   "metadata": {},
   "source": [
    "### Next step: stochastic volatility\n",
    "\n",
    "Stochastic volatility should be feasible with similar methods, but requires a bit more of a change from the existing code. The issue here is `LinearStateSpaceProblem` in `DifferenceEquations.jl` is currently set up only for Linear Time Invariant systems, and this extension makes it time varying. Fortunately, iteration is just a for loop, so this will be a nice exercise in demonstrating how to write a function compatible with the reverse mode automatic differentiation system in Zygote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b19f08a-b549-44e9-b88f-5ededa56e338",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: Random not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Random not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:3"
     ]
    }
   ],
   "source": [
    "# Simulate T observations from a random initial condition\n",
    "T = 50\n",
    "Random.seed!(12435) #Fix seed to reproduce data\n",
    "dof = 4 #Student t degrees of freedom\n",
    "shockdist = TDist(dof) #Shocks are student-t\n",
    "ρ_σ = 0.5 #Persistence of log volatility\n",
    "μ_σ = 1. #Mean of (prescaling) volatility\n",
    "σ_σ = 0.1 #Volatility of volatility\n",
    "\n",
    "# draw from t scaled by approximate invariant variance) for the initial condition\n",
    "x_iv = sol.x_ergodic_var * rand(shockdist,sol.n_x)\n",
    "\n",
    "# Generate noise sequence\n",
    "noise = Matrix(rand(shockdist,T)') # the ϵ shocks are \"noise\"\n",
    "volshocks = Matrix(rand(MvNormal(T,1.0))') # the volatility shocks are log-normal\n",
    "obsshocks = reshape(rand(MvNormal(T*sol.n_z,p_f[:Ω_1])), sol.n_z, T) #Gaussian observation noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0e2c6-9cf2-4f9f-b1ff-a64fe4889d35",
   "metadata": {},
   "source": [
    "The following code is an extension of the code for simulating data from linear state space models in `DifferenceEquations.jl`, extended to add a stochastic volatility element of the form\n",
    "$$vol_t = \\rho_\\sigma * vol_{t-1} + (1 - \\rho_\\sigma) * \\mu_\\sigma + \\sigma_\\sigma * \\zeta_{t-1}$$\n",
    "where $exp(vol_t)$ is the standard deviation of the shock at time $t$, and $\\zeta_{t}$ are i.i.d. normal shocks. (We could make them non-normal, but this is fine for now).\n",
    "\n",
    "The one thing to note about the way the code is implemented is that it uses exclusively in-place operations inside the loop, which means that it fixes the sequence once then updates it rather than allocating a new variable at each step in the loop. This is a useful programming trick for optimizing memory usage and speed, which is why we used it in the library: see https://book.sciml.ai/ for a wonderful course on writing super efficient Julia code. But it's kind of hard to read, and more importantly, would create problems down the road if we tried to use it directly inside our estimation without some additional tricks. So I'll rewrite it in a simpler way for that task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c13f9e00-fe18-4885-bf50-d0cfa1fa7a38",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: sol not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: sol not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:2"
     ]
    }
   ],
   "source": [
    "#Extract solution matrices\n",
    "A = sol.A\n",
    "B = sol.B\n",
    "C = sol.C\n",
    "D = sol.D\n",
    "\n",
    "# Initialize\n",
    "u = [zero(x_iv) for _ in 1:T]\n",
    "u[1] .= x_iv\n",
    "vol = [zeros(1) for _ in 1:T]\n",
    "vol[1] = [μ_σ] #Start at mean: could make random but won't for now\n",
    "#Allocate sequence\n",
    "z = [zeros(size(C, 1)) for _ in 1:T] \n",
    "mul!(z[1], C, u[1])  # update the first of z\n",
    "for t in 2:T\n",
    "        mul!(u[t], A, u[t - 1]) # sets u[t] = A * u[t - 1]\n",
    "        mul!(vol[t], ρ_σ, vol[t-1])\n",
    "        vol[t] .+= (1 - ρ_σ) * μ_σ\n",
    "        mul!(vol[t], σ_σ, view(volshocks, :, t - 1),1,1) # adds σ_σ * volshocks[t-1] to vol[t]\n",
    "        mul!(u[t], exp(vol[t][]) .* B, view(noise, :, t - 1),1,1)\n",
    "        mul!(z[t], C, u[t]) \n",
    "end\n",
    "for t in 1:T #Add observation noise\n",
    "        z[t] .+= view(obsshocks,:,t)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba4e3821-df65-43a7-b01c-cfe9a233758b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: z not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: z not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:1"
     ]
    }
   ],
   "source": [
    "z_data = hcat(z...)\n",
    "plot(z_data') #Plot k and z from simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c49429d-433d-40f5-a1c4-ec419ea0e60f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: vol not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: vol not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:1"
     ]
    }
   ],
   "source": [
    "plot(hcat(vol...)') #Plot the latent volatility state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23bc862-885e-496f-bfdb-9ff1ec85fa54",
   "metadata": {},
   "source": [
    "That worked fine for simulation, so the next step is to create the likelihood function corresponding to that simulation. A simple approach would just be take that code and replace the sampling components with density evaluations, which is essentially how our code in `DifferenceEquations.jl` works.\n",
    "Unfortunately, I can't do that exactly because the AD framework, `Zygote`, [doesn't allow mutation](https://fluxml.ai/Zygote.jl/latest/limitations/). What this means is that, because it works by following your function along its execution trace, it needs to be able to have a unique address for each evaluation, which gets messed up if your functions work by reallocating the values in an existing object. In practice, this can be resolved either by functional programming or by hiding the non-functional parts away from the AD system.  \n",
    "There are a few ways to do that in practice.\n",
    "\n",
    "- One way is by hiding the mutation in an explicitly constructed adjoint function, creating a custom `rrule` in `ChainRules.jl`. This is feasible and can yield highly performant code, which is what we did for the (very similar) adjoint formulas in `DifferenceEquations.jl`. This is also a bit tedious and involves math (mostly [transposing matrices](https://juliadiff.org/ChainRulesCore.jl/dev/maths/arrays.html)), so I'm going to avoid it for now.\n",
    "    \n",
    "- Alternately, it ought to be doable by cleaning up the function to avoid the allocation parts. I think that will make things easier than the current code, which uses it for speed and memory reasons, not because of Zygote. Certainly getting rid of all those `mul!` statements ought to make the code easier to read. The only really tricky part about this is that to avoid preallocating the sequences, I will use a special data structure called Zygote.Buffer() which stores the values but isn't touched by the AD, and wrap the code containing the buffer in a function. This is maybe not so performant, but it's easy.\n",
    "    \n",
    "*Note to applied researchers for whom the above discussion sounded scary* (eg, me before I spent a hunk of time learning about this stuff): for most common models and operations the AD systems are fully established and you will never have to build these constructs yourself. And if you do end up needing to build custom adjoints because of some gnarly custom modeling code, tools are getting easier to use: the Python-based AD system JAX has a nice feature called [automatic transposition](https://jax.readthedocs.io/en/latest/notebooks/Custom_derivative_rules_for_Python_code.html) where all you have to do is write a function that computes the derivative of your function of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e5d300f-b79e-4390-a88b-c550c5c144b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: sol not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: sol not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:17"
     ]
    }
   ],
   "source": [
    "#Likelihood evaluation function using `Zygote.Buffer()` to create internal arrays that don't interfere with gradients.\n",
    "function svlikelihood2(A,B,C,D,x_iv,Ω_1,μ_σ,ρ_σ,σ_σ,observables,noise,volshocks) #Accumulate likelihood\n",
    "    # Initialize\n",
    "    T = size(observables,2)\n",
    "    u = Zygote.Buffer([zero(x_iv) for _ in 1:T]) #Fix type: Array of vector of vectors?\n",
    "    vol = Zygote.Buffer([zeros(1) for _ in 1:T]) #Fix type: Array of vector of vectors?\n",
    "    u[1] = x_iv \n",
    "    vol[1] = [μ_σ] #Start at mean: could make random but won't for now\n",
    "    for t in 2:T\n",
    "        vol[t] = ρ_σ * vol[t-1] .+ (1 - ρ_σ) * μ_σ .+ σ_σ * volshocks[t - 1]\n",
    "        u[t] = A * u[t - 1] .+ exp.(vol[t]) .* (B * noise[t - 1])[:]\n",
    "    end\n",
    "    loglik = sum([logpdf(MvNormal(Diagonal(Ω_1 * ones(size(C, 1)))), observables[t] .- C * u[t]) for t in 1:T])\n",
    "    return loglik\n",
    "end\n",
    "\n",
    "ll = svlikelihood2(sol.A,sol.B,sol.C,sol.D,x_iv,p_f[:Ω_1],μ_σ,ρ_σ,σ_σ,z_data,noise,volshocks)\n",
    "\n",
    "gradient(x_iv->svlikelihood2(sol.A,sol.B,sol.C,sol.D,x_iv,p_f[:Ω_1],μ_σ,ρ_σ,σ_σ,z_data,noise,volshocks),[0., 0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb28d3a7-4dab-4cb2-ad80-b851ff9ff192",
   "metadata": {},
   "source": [
    "As the gradient code demonstrates, automatic differentiation works for this version of the likelihood function.  Now let's stick it in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e34c15d-0d4d-442e-9be1-aa0d763c12cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rbc_1_svt_jointseq (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turing model definition\n",
    "@model function rbc_1_svt_jointseq(z, m, p_f, dof, cache, settings)\n",
    "    α ~ Uniform(0.2, 0.8)\n",
    "    β ~ Uniform(0.5, 0.99)\n",
    "    ρ_σ ~ Beta(2.625, 2.625) #Persistence of log volatility\n",
    "    μ_σ ~ Normal(1., 0.5) #Mean of (prescaling) volatility\n",
    "    σ_σ ~ Uniform(0.03, 0.3) #Volatility of volatility\n",
    "    p_d = (; α, β)\n",
    "    T = size(z, 2)\n",
    "    xnought ~ filldist(TDist(dof),m.n_x) #Initial shocks \n",
    "    ϵ_draw ~ filldist(TDist(dof),m.n_ϵ * T) #Shocks are t-distributed!\n",
    "    ϵ = reshape(ϵ_draw, m.n_ϵ, T)\n",
    "    vsdraw ~ MvNormal(T, 1.0)\n",
    "    volshocks = reshape(vsdraw,1,T)   \n",
    "    sol = generate_perturbation(m, p_d, p_f, Val(1); cache, settings) \n",
    "    if !(sol.retcode == :Success)\n",
    "        @addlogprob! -Inf\n",
    "        return\n",
    "    end\n",
    "    x_iv = sol.x_ergodic_var * xnought #scale initial condition to ergodic variance\n",
    "    @addlogprob! svlikelihood2(sol.A,sol.B,sol.C,sol.D,x_iv,p_f[:Ω_1],μ_σ,ρ_σ,σ_σ,z,ϵ,volshocks)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "581f7b20-eab1-4d8f-be31-cf0bc6251a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: model_rbc not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model_rbc not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:1"
     ]
    }
   ],
   "source": [
    "cache = SolverCache(model_rbc, Val(1),  [:α, :β])\n",
    "settings = PerturbationSolverSettings(; print_level = 0)\n",
    "p_f = (ρ = 0.2, δ = 0.02, σ = 0.01, Ω_1 = 0.01) # Fixed parameters\n",
    "z = z_data # simulated in previous steps\n",
    "turing_model2 = rbc_1_svt_jointseq(z, model_rbc, p_f, dof, cache, settings) # passing observables from before \n",
    "\n",
    "n_samples = 1000\n",
    "n_adapts = 100\n",
    "δ = 0.65\n",
    "alg = NUTS(n_adapts,δ)\n",
    "chain_2_joint = sample(turing_model2, alg, n_samples; progress = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba7829e9-a0aa-4b30-989b-a9999e54f970",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: chain_2_joint not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chain_2_joint not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:1"
     ]
    }
   ],
   "source": [
    "plot(chain_2_joint[[\"α\"]]; colordim=:parameter, legend=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1544a8d2-16ec-4b00-b28f-12b749daa2fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: chain_2_joint not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chain_2_joint not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:1"
     ]
    }
   ],
   "source": [
    "plot(chain_2_joint[[\"β\"]]; colordim=:parameter, legend=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9316d2c2-1209-4ca7-9c14-fc7e766504d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: chain_2_joint not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chain_2_joint not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:3"
     ]
    }
   ],
   "source": [
    "#Plot true and estimated latents to see how well we backed them out\n",
    "symbol_to_int(s) = parse(Int, string(s)[9:end-1])\n",
    "ϵ_chain = sort(chain_2_joint[:, [Symbol(\"ϵ_draw[$a]\") for a in 1:50], 1], lt = (x,y) -> symbol_to_int(x) < symbol_to_int(y))\n",
    "tmp = describe(ϵ_chain)\n",
    "ϵ_mean = tmp[1][:, 2]\n",
    "ϵ_std = tmp[1][:, 3]\n",
    "plot(ϵ_mean[1:end], ribbon=2 * ϵ_std[1:end], label=\"Posterior mean\", title = \"First-Order Joint: Estimated Shocks\")\n",
    "plot!(noise', label=\"True values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28ef5d5a-1418-4910-ae89-443e97113795",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: chain_2_joint not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chain_2_joint not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\fm007\\Documents\\GitHub\\MacroModelling.jl\\nonlinear\\NonGaussianRBC.ipynb:3"
     ]
    }
   ],
   "source": [
    "#Plot true and estimated volatility shocks to see how well we backed them out\n",
    "symbol_to_int(s) = parse(Int, string(s)[8:end-1])\n",
    "v_chain = sort(chain_2_joint[:, [Symbol(\"vsdraw[$a]\") for a in 1:50], 1], lt = (x,y) -> symbol_to_int(x) < symbol_to_int(y))\n",
    "tmp = describe(v_chain)\n",
    "v_mean = tmp[1][:, 2]\n",
    "v_std = tmp[1][:, 3]\n",
    "plot(v_mean[1:end], ribbon=2 * v_std[1:end], label=\"Posterior mean\", title = \"First-Order Joint: Estimated Volatility Shocks\")\n",
    "plot!(volshocks', label=\"True values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775ae96-02d9-40ea-9b4e-7fff43e3c24d",
   "metadata": {},
   "source": [
    "That did it! With a little bit of fiddling with data structures to handle some technical issues with automatic differentiation, we built a working probability model incorporating economic structure, non-Gaussian errors, and stochastic volatility. There are plenty of code optimizations that could be done if we wanted to make this faster (see https://book.sciml.ai/ for a comprehensive guide to writing fast Julia), but this gave us a simple working version to start from, that performs okay. The estimation accuracy isn't great here, but I suspect that's a feature of the model rather than the procedure. Specifically, there's just not a lot of info in the data points to back out the time-varying volatilities, so the posterior ends up quite wide and the rest of the parameters are correspondingly harder to estimate. I may consider tighter priors, longer data, or other features improving identification, for future runs.\n",
    "\n",
    "In terms of economic content, this kind of model is likely to be extremely relevant for studying data post-pandemic, with huge outliers best matched by heavy-tailed distributions, and for dealing with questions where changes in volatility help identify responses ([e.g.](https://itskhoki.com/papers/Mussa.pdf)). Moreover, nothing relied explicitly on the form of the distribution or the volatility shocks, so you could easily incorporate features like skewed shock distributions or even stochastic skewness. Of course, the certainty equivalent case is somewhat limiting here, but you can capture the first order effects of volatility using higher order perturbation solution, which we provide, and, in principle, extend further to more general nonlinear solvers.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
