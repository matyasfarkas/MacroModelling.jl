

using MacroModelling
import Turing, StatsPlots
import LinearAlgebra as ‚Ñí





@model RBC begin
	K[0] = (1 - Œ¥) * K[-1] + I[0]
	Y[0] = Z[0] * K[-1]^Œ±
	Y[0] = C[0] + I[0]
	1 / C[0]^Œ≥ = Œ≤ / C[1]^Œ≥ * (Œ± * Y[1] / K[0] + (1 - Œ¥))
	Z[0] = (1 - œÅ) + œÅ * Z[-1] + œÉ * œµ[x]
end


@parameters RBC verbose = true begin 
    œÉ = 0.01
    Œ± = 0.5
    Œ≤ = 0.95
    œÅ = 0.2
    Œ¥ = 0.02
    Œ≥ = 1
end

zsim = simulate(RBC)
zsim1 = hcat(zsim([:K,:Z],:,:)...)
zdata = ‚Ñí.reshape(zsim1,2,40)

# z_rbc1 = hcat(zsim...)
# z_rbc1 = ‚Ñí.reshape(z_rbc1,size(RBC.var,1),40)



solution = get_solution(RBC, RBC.parameter_values, algorithm = :second_order)

Turing.@model function loglikelihood_scaling_function(m, data, observables)
    œÉ     ~ MacroModelling.Beta(0.01, 0.02, ŒºœÉ = true)
    Œ±     ~ MacroModelling.Beta(0.5, 0.1, ŒºœÉ = true)
    Œ≤     ~ MacroModelling.Beta(0.95, 0.01, ŒºœÉ = true)
    œÅ     ~ MacroModelling.Beta(0.2, 0.1, ŒºœÉ = true)
    Œ¥     ~ MacroModelling.Beta(0.02, 0.05, ŒºœÉ = true)
    Œ≥     ~ Turing.Normal(1, 0.05)
    
    #    initial_conditions ~ Turing.filldist(Turing.TDist(4),m.timings.nPast_not_future_and_mixed) # Initial conditions 

    initial_conditions ~ Turing.filldist(Turing.Normal(0,1),m.timings.nPast_not_future_and_mixed) # Initial conditions 

    solution = get_solution(m, [œÉ, Œ±, Œ≤, œÅ, Œ¥, Œ≥], algorithm = :second_order)

    if solution[end] != true
        return Turing.@addlogprob! Inf
    end

    ùêí‚ÇÅ = hcat(solution[2][:,1:m.timings.nPast_not_future_and_mixed], zeros(m.timings.nVars), solution[2][:,m.timings.nPast_not_future_and_mixed+1:end])

    # œµ_draw ~ Turing.filldist(Turing.TDist(4), m.timings.nExo * size(data, 2)) #Shocks are t-distributed!
    œµ_draw ~ Turing.filldist(Turing.Normal(4), m.timings.nExo * size(data, 2)) #Shocks are t-distributed!

    œµ = reshape(œµ_draw, m.timings.nExo,  size(data, 2))

    state = zeros(typeof(initial_conditions[1]),m.timings.nVars, size(data, 2)+1)

    # state[m.timings.past_not_future_and_mixed_idx,1] .= initial_conditions

    aug_state = [initial_conditions
    1 
    œµ[:,1]]
    state[:,1] .=  ùêí‚ÇÅ * aug_state + solution[3] * ‚Ñí.kron(aug_state, aug_state) / 2 

    for t in 2:size(data, 2)+1
        aug_state = [state[m.timings.past_not_future_and_mixed_idx,t-1]
                    1 
                    œµ[:,t-1]]
        state[:,t] .=  ùêí‚ÇÅ * aug_state + solution[3] * ‚Ñí.kron(aug_state, aug_state) / 2 
    end

    observables_index = sort(indexin(observables, m.timings.var))

    state_deviations = data[:,1:end] - state[observables_index,2:end]

    Turing.@addlogprob! sum([Turing.logpdf(Turing.MvNormal(‚Ñí.Diagonal(ones(size(state_deviations,1)))), state_deviations[:,t]) for t in 1:size(data, 2)])
end

n_samples = 1000

loglikelihood_scaling = loglikelihood_scaling_function(RBC, zdata,[:K,:Z])

samps = Turing.sample(loglikelihood_scaling, Turing.NUTS(), n_samples, progress = true)#, init_params = sol)

