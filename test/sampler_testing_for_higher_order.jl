
import Pkg; Pkg.instantiate();

using MacroModelling
import Turing, StatsPlots
Turing.setadbackend(:forwarddiff)

@model RBC begin
	K[0] = (1 - Œ¥) * K[-1] + I[0]
	Y[0] = Z[0] * K[-1]^Œ±
	Y[0] = C[0] + I[0]
	1 / C[0]^Œ≥ = Œ≤ / C[1]^Œ≥ * (Œ± * Y[1] / K[0] + (1 - Œ¥))
	Z[0] = (1 - œÅ) + œÅ * Z[-1] + œÉ * œµ[x]
end


@parameters RBC verbose = true begin 
    œÉ = 0.01
    Œ± = 0.5
    Œ≤ = 0.95
    œÅ = 0.2
    Œ¥ = 0.02
    Œ≥ = 1
end

get_SS(RBC)

# plot_irf(RBC)

get_solution(RBC)



Turing.@model function loglikelihood_function(m)
    œÉ     ~ MacroModelling.Beta(0.01, 0.02, ŒºœÉ = true)
    Œ±     ~ MacroModelling.Beta(0.5, 0.1, ŒºœÉ = true)
    Œ≤     ~ MacroModelling.Beta(0.95, 0.01, ŒºœÉ = true)
    œÅ     ~ MacroModelling.Beta(0.2, 0.1, ŒºœÉ = true)
    Œ¥     ~ MacroModelling.Beta(0.02, 0.05, ŒºœÉ = true)
    Œ≥     ~ Turing.Normal(1, 0.05)
    
    Turing.@addlogprob! sum(get_solution(m,[œÉ, Œ±, Œ≤, œÅ, Œ¥, Œ≥])[2]) / 1e8
end

# using LinearAlgebra

# Z‚ÇÅ‚ÇÅ = randn(10,10)
# ZÃÇ‚ÇÅ‚ÇÅ = svd(Z‚ÇÅ‚ÇÅ)
# ZÃÇ‚ÇÅ‚ÇÅ |>inv

# ZÃÇ‚ÇÅ‚ÇÅ.S .|> inv
# ZÃÇ‚ÇÅ‚ÇÅ.Vt |> inv

# (ZÃÇ‚ÇÅ‚ÇÅ.U * inv(diagm(ZÃÇ‚ÇÅ‚ÇÅ.S)) * ZÃÇ‚ÇÅ‚ÇÅ.Vt)'
# inv(Z‚ÇÅ‚ÇÅ)

# Z‚ÇÇ‚ÇÅ = randn(10,10)

# D      = Z‚ÇÇ‚ÇÅ / ZÃÇ‚ÇÅ‚ÇÅ
# D      = Z‚ÇÇ‚ÇÅ / Z‚ÇÅ‚ÇÅ



loglikelihood = loglikelihood_function(RBC)


n_samples = 10


# using Zygote
# Turing.setadbackend(:zygote)
# samps = Turing.sample(loglikelihood, Turing.NUTS(), n_samples, progress = true)#, init_params = sol)




Turing.@model function loglikelihood_second_order_function(m)
    œÉ     ~ MacroModelling.Beta(0.01, 0.02, ŒºœÉ = true)
    Œ±     ~ MacroModelling.Beta(0.5, 0.1, ŒºœÉ = true)
    Œ≤     ~ MacroModelling.Beta(0.95, 0.01, ŒºœÉ = true)
    œÅ     ~ MacroModelling.Beta(0.2, 0.1, ŒºœÉ = true)
    Œ¥     ~ MacroModelling.Beta(0.02, 0.05, ŒºœÉ = true)
    Œ≥     ~ Turing.Normal(1, 0.05)
    soll = get_solution(m,[œÉ, Œ±, Œ≤, œÅ, Œ¥, Œ≥], algorithm = :second_order)
    println(soll[end])
    Turing.@addlogprob! sum(soll[3]) / 1e6
end


loglikelihood_second_order = loglikelihood_second_order_function(RBC)

#samps = Turing.sample(loglikelihood_second_order, Turing.NUTS(), n_samples, progress = true)#, init_params = sol)




data = randn(1,10)

#Likelihood evaluation function using `Zygote.Buffer()` to create internal arrays that don't interfere with gradients.
function svlikelihood2(ùêí‚ÇÅ, ùêí‚ÇÇ, x_iv,Œ©_1,observables,noise) #Accumulate likelihood
    # Initialize
    T = size(observables,2)
    u = ([zero(x_iv) for _ in 1:T]) #Fix type: Array of vector of vectors?
    # vol = Zygote.Buffer([zeros(1) for _ in 1:T]) #Fix type: Array of vector of vectors?
    u[1] = x_iv 
    ùêí‚ÇÅ = [ùêí‚ÇÅ[:,1:m.timings.nFuture_not_past_and_mixed] zeros(size(ùêí‚ÇÅ,1)) ùêí‚ÇÅ[:,m.timings.nFuture_not_past_and_mixed+1:end]]
    #vol[1] = [Œº_œÉ] #Start at mean: could make random but won't for now
    for t in 2:T
        #vol[t] = œÅ_œÉ * vol[t-1] .+ (1 - œÅ_œÉ) * Œº_œÉ .+ œÉ_œÉ * volshocks[t - 1]
        aug_state = [u[t-1]
                        1 
                        noise[:,t-1]]
        # sol[3]'  |>Matrix
        u[t] =  ùêí‚ÇÅ * aug_state #+ ùêí‚ÇÇ * kron(aug_state, aug_state) / 2 
        # u[t] = A * u[t - 1] .+ exp.(vol[t]) .* (B * noise[t - 1])[:]
    end
    loglik = sum([logpdf(MvNormal(‚Ñí.Diagonal(Œ©_1 * ones(size(observables,1)))), observables[:,t] .- ‚Ñí.I * u[t][1:size(x_iv,1)]) for t in 1:T])
    return loglik
end
 
Turing.@model function loglikelihood_scaling_function(m, data)
    œÉ     ~ MacroModelling.Beta(0.01, 0.02, ŒºœÉ = true)
    Œ±     ~ MacroModelling.Beta(0.5, 0.1, ŒºœÉ = true)
    Œ≤     ~ MacroModelling.Beta(0.95, 0.01, ŒºœÉ = true)
    œÅ     ~ MacroModelling.Beta(0.2, 0.1, ŒºœÉ = true)
    Œ¥     ~ MacroModelling.Beta(0.02, 0.05, ŒºœÉ = true)
    Œ≥     ~ Turing.Normal(1, 0.05)
    T= size(data, 2)
    initial_conditions ~ Turing.filldist(Turing.TDist(4),m.timings.nVars) # Initial conditions 

    solution = get_solution(m,[œÉ, Œ±, Œ≤, œÅ, Œ¥, Œ≥], algorithm = :second_order)

    if !solution[end]
        return Turing.@addlogprob! Inf
    end

    calculate_covariance_ = calculate_covariance_AD(solution[2], T = m.timings, subset_indices = collect(1:m.timings.nVars))

    long_run_covariance = calculate_covariance_(solution[2])

    x_iv = long_run_covariance * initial_conditions #scale initial condition with ergodic variance

    œµ_draw ~ Turing.filldist(Turing.TDist(4), m.timings.nExo * T) #Shocks are t-distributed!
    œµ = reshape(œµ_draw, size(m.exo,1), T)

    Turing.@addlogprob! svlikelihood2(solution[2], solution[3],x_iv,0.01,data,œµ) 
end

loglikelihood_scaling = loglikelihood_scaling_function(RBC, data)

samps = Turing.sample(loglikelihood_scaling, Turing.NUTS(), n_samples, progress = true)#, init_params = sol)

svlikelihood2(solution[2], solution[3],x_iv,0.01,data,rand(1,10)) 
x_iv = rand(2)
noise[:,t-1]
solution[3]